The Rise of Artificial Intelligence
Generally, when most hear the words artificial intelligence, the first thing that comes to mind is menacing robots. However, this is not accurate. Artificial intelligence is an imitation of human knowledge that is programmed in different machines, using algorithms, to simulate the thought process and actions of humans. The first concepts for AI started in the 1950s, where many mathematicians, scientists, and philosophers explored the possibility of machines that problem solved and made decisions like humans. Over the years, AI research has grown by leaps and bounds, and many programs created, are used daily. From virtual assistants like Siri to the use of autopilot on an aircraft, artificial intelligence is everywhere.
Further research on AI raises awareness and helps those gain the knowledge to understand how beneficial or dangerous this technology could be. As artificial intelligence continues to develop, many question whether A.I. will become more advanced and have an advantage over humans, causing singularity to occur. Thus, leading to the evolution of superintelligences that become smarter than humans. Instead of taking over humanity, AI and humans can merge intelligence, and work together, integrating for maximum efficiency. AI confinement protocols can serve as the solution to slow down the effects of singularity and allow humans to benefit from the superintelligences formed safely.
History of Artificial Intelligence
Artificial Intelligence derives from an area of computer science used to create intelligent programs that can problem solve, plan, learn, recognize speech, etc. According to Weber (2019), this includes areas, “which human brainpower is simply too limited or would take too long to be useful” (p. 4, para. 10).  Back then, when the ideas of artificial intelligence were first presented, computers were the primary source looked at to house such intellectual programs. However, in the 1950s, computers were costly and could not store commands given, which is essential in the development of the AI system. After many modifications, computers could now not only execute all sorts of commands but had the ability to store them as well. From this modernization, many were able to explore the different realms of artificial intelligence more in-depth than before.
Five years after the first notions of artificial intelligence were discussed, birth was given to the first proof of that concept and was called Logic Theorist. Created by Cliff Shaw, Herbert Simon, and Allen Newell, “The Logic Theorist was a program designed to mimic the problem-solving skills of a human and was funded by Research and Development (RAND) Corporation” (Anyoha, 2017, p. 3).  Considered a thinking machine, the Logic Theorist was engineered to prove theorems from Principia Mathematica using information relating to the world around it. This cognitive simulation is said to be the first working AI program that showed some aspect of problem-solving like humans. The team’s progress from such a creation had a very significant impact on the field of artificial intelligence and served as the catalyst that assisted in the flourishing of AI research over the next half-century.
Today, artificial intelligence is encountered daily. From email filters to those nudging suggestions, from social media accounts to customer service chatbots. The application of artificial intelligence is said to help make life more efficient. People can connect with friends and family, request rides using sharing apps, and navigate to places unknown. It seems that AI has made it possible for people to accomplish much more by working together with its intelligent software.
For the future of artificial intelligence, AI language and self-driving cars are now in progress. AI language will cover conversations that are smoother between humans and automated machines, as well as being able to translate a conversation between two languages in present time. On the other side of the horizon, concepts of driverless cars have been announced, and much work is being down to produce a proven concept within the next 20 years. In the beginning, “artificial intelligence started as a field whose goal was to replicate human-level intelligence in a machine” (Brooks, 1988, para. 2). The goal now of those researching and creating AI is to produce programs that surpass human capabilities cognitively in many if not all tasks.
 Artificial Intelligence is given the capability to learn in an intelligent way, by permitting machines the ability to learn from experience and in turn, perform tasks that are similar to that of humans. Some components that make up artificial intelligence are; machine learning, deep learning, and cognitive computing. These elements give AI the skills to process massive amounts of big data that is generated in the world, regularly. IT professionals write algorithms that allow AIs to sift through and analyze data analytics that could be useful for things such as figuring out consumer habits for a business. According to an article on AI and big data, “first data is fed into the AI engine, marking the AI smarter. Next, less human interaction is needed for the AI to run properly, and finally, the less AI needs people to run, the closer society comes to realizing the full potential of artificial intelligence” (Maryville University, n.d., para. 13). With little to no human dealings and massive amounts of data being fed to AI systems, they can take on more tasks, solve more problems, and over time, learn more to become smarter than humans.
Argument
At the rate artificial intelligence creators are going now, further advancements in the AI realm will continue to tip the scale allowing much room for singularity to occur. According to Chalmers (2012), “a singularity is a rapid increase in intelligence to superintelligence (intelligence of far greater than human levels), as each generation of intelligent systems creates more intelligent systems in turn” (p. 147). Ultimately, this event would signal that moment in time when artificial intelligence changes and exceeds human intellect altogether. This would be due to the development of AI that learns to better itself and create other versions of artificial intelligence that are improved versions of itself as well. At this point, humans will no longer bear control over these systems. The control would shift to that of the superior superintelligence.
The rise of artificial intelligence is a global societal issue because people have different perspectives on how dangerous or beneficial this technology could be for the world. Some praise AI for being the best invention today. According to a study done by the Brookings Institute (2018), “Thirty-eight percent felt artificial intelligent robots would make their lives easier in the next five years” (para. 8). Facilitating conversations via chat bots, assisting to perform light housekeeping, and controlling homes with the touch of a button are what most look forward to. Whereas others are skeptic and believe it is a mistake giving AI the ability to learn on a more profound level, leading to artificial intelligent domination that will be dangerous for humanity. It is said that the singularity is inevitable, and as creators continue to better previous versions of AI models, the systems will continue to learn rapidly, allowing them to become smarter than humans. Nevertheless, it does not have to be negative. Transparency will play a crucial role in the solution to this problem. With the help of creators being more transparent about the possible uses for AI and the needs of humanity, it could be shown that both AI and humans can work together.
Think about how resourceful it would be to work with AI that can offer assistance with daily operations, and does not have to be extensively trained, looked after, or told what to do repeatedly. Artificial intelligence is created to have the capacity and speed of processing information quicker and far beyond what any human can process. Through the application of deep learning, neural connections of AI, “focuses on computational models for information representation that exhibit similar characteristics to that of the neocortex” (Arel, Rose, & Karnowski, 2010, para.10). Algorithms used in deep learning are designed to mimic neural networks of the human brain, where various layers allow the AI to learn data repeatedly, refining on each outcome. The more the AI learns from the application of deep learning, the better they will be able to perform and make decisions. This could be beneficial in the example of AI and humans that work together. However, for this to occur, it must be understood that adequately knowing how to control the artificial neural networks of an AI system is the key to managing and slowing down the effects of singularity.
Solutions
From the start of artificial intelligence, there have been significant concerns surrounding AI like; what it is exactly, how it is used, and where does it get the data it learns from. According to Rossi (2019), “these concerns are among the obstacles that hold AI back or that cause worry for current AI users, adopters, and policymakers” (para. 6). The solution would be to improve the transparency of those who create artificial intelligence, giving humanity a chance to understand just how AI is advancing. Being more transparent about plans for AI could help people comprehend artificial intelligence more, not be so fearful of what AI can do, and make the connections on how the world is already interacting with AI in various ways. Overall, improving people’s attitudes towards this type of technology.
Once the connection is made, delving deeper into that connection with AI can help to further make people’s lives more efficient by working together for the better. For example, physicians have busy schedules. AI is now being integrated to aid doctors with various tasks, including analyzing swabs faster, designing treatment plans, and assisting with data mining through medical records. Artificial intelligence has been helpful in aiding in the tedious tasks mentioned above. Working together with AI gives doctors the time to perform other functions and work more effectively and efficiently. 
The second solution would be to create an AI confinement protocol that would be used to uphold the safety of artificial intelligence by sealing the AI in hardware that prevents it from exchanging information with outside sources. The AI would only be able to learn from data that is programmed by the creator. If the exchange of information were to occur, someone could get their hands on crucial information and or develop hazardous software such as an artificially intelligent virus. According to an article on leak proofing the singularity, “the consequences would be unquestionably disastrous and would pose risks currently unseen in malware with subhuman intelligence” (Yampolskiy, 2011, para. 9). A malicious virus can spread fast, go without being detected, and can infect and encrypt all file systems. Here, there is a possibility of turning the AI system against the creator who controls it. 
 So, properly controlling A.I. and using it for good would be essential. Keeping the AI’s data incased in the system it is in, will help to contain its information to its own network, while still upholding its intellectual integrity. The creator would program algorithms that would allow the AI to take part in machine learning but on a limited scale since the AI will not be able to learn too much on its own. This would help to slow down the effects of singularity because the artificial intelligence would not be able to send or receive information from other sources, thus allowing humans better control over how quickly an artificial intelligence can learn.
Ethical Outcomes and Issues
Over the years, many ethical concerns, both positive and negative, have formed regarding the use of artificial intelligence. One positive ethical outcome from the solution of transparency is that people will feel more connected to artificial intelligence and the process of how AI is used. One ethical issue related to this outcome would be that the creators do not feel the need to be transparent with the world about the workings of artificial intelligence. They can be reluctant or refuse to share information altogether. Another ethical issue from this outcome would be that people will still not feel that they gained a better understanding of what AI is and continue making ill-informed decisions about the use of artificial intelligence.
 A negative ethical outcome from the solution of creating a confinement protocol is that creators will not be able to find a way to seal the artificial intelligence in its own hardware properly. Thus, not stopping the AI from exchanging information with other networks. An ethical issue related to this outcome would be that creators are not equipped with the knowledge to know how to confine and control artificial intelligence correctly. This could signal why a working confinement protocol has not quite been mastered yet. Another ethical issue related to this outcome would be that the artificial intelligence would be able to continue to learn without the assistance from human input, and with the exchanging of information AI can grow smarter, and humans would no longer be able to control the systems.
Conclusion
In conclusion, AI has a long history of concepts and research that have bought many systems into fruition. Intelligent software and algorithms are programmed into many of the systems we use daily, and it seems that artificial intelligence is the wave of the future. Further research on this topic is imperative to helping others gain knowledge of this trending phenomenon, which could lead to better understanding and more informed decisions on whether AI is beneficial or dangerous to humans. The rise of artificial intelligence is a global societal issue for all because AI impacts everyone around the world. There are countless advancements with artificial intelligence, and as the projects get better, more data and more in-depth learning is needed for AI to work at its best. Deep learning and neural networks mimic the biological structure of the human brain, allowing artificial intelligence to learn without human input. From this singularity can occur, pushing AI to the evolution of superintelligences that become smarter than humans. However, instead of taking over humanity, AI and humans can merge intelligence, and work together, integrating for maximum efficiency. AI confinement protocols will serve as the solution to slow down the effects of singularity and allow humans to safely benefit from the superintelligences formed.



In this topic, we are going to provide an essay on Artificial Intelligence. This long essay on Artificial Intelligence will cover more than 1000 words, including Introduction of AI, History of AI, Advantages and disadvantages, Types of AI, Applications of AI, Challenges with AI, and Conclusion. This long essay will be helpful for students and competitive exam aspirants.
Artificial Intelligence is a combination of two words Artificial and Intelligence, which refers to man-made intelligence. Therefore, when machines are equipped with man-made intelligence to perform intelligent tasks similar to humans, it is known as Artificial Intelligence. It is all about developing intelligent machines that can simulate the human brain and work & behave like human beings.
We can define AI as, "Artificial Intelligence is a branch of computer science that deals with developing intelligent machines which can behave like human, think like human, and has ability to take decisions by their own."
With AI, machines can have human-based skills such as learning, reasoning, and solving logical problems.
AI is one of the fastest-growing technology that is making human life much easier by providing solutions for complex problems. It has also brought different opportunities for everyone, and hence it is a very demanding technology in the market.
History of Artificial Intelligence
Artificial intelligence is assumed a new technology, but in reality, it is not new. The researchers in the field of AI are much older. It is said that the concept of intelligent machines was found in Greek Mythology. Below are some keystones in the development of AI:
In the year 1943, Warren McCulloch and Walter pits proposed a model of Artificial neurons.
In the year 1950, Alan Turing published a "Computer Machinery and Intelligence" paper in which he introduced a test, known as a Turing Test. This test is used to determine intelligence in machines by checking if the machine is capable of thinking or not.
In the year 1956, for the first time, the term Artificial Intelligence was coined by the American Computer scientist John McCarthy at the Dartmouth Conference. John McCarthy is also known as the Father of AI.
In the year 1972, the first full-scale intelligent humanoid robot, WABOT1, was created in Japan.
In the year 1980, AI came with the evolution of Expert Systems. These systems are computer programs, which are designed to solve complex problems.
In the year 1997, IBM Deep Blue beat world chess champion Gary Kasparov and became the first computer to defeat a world chess champion.
In the year 2006, AI came into the business world. World's top companies like Facebook, Twitter, and Netflix also started using AI in their applications.
Advantages & disadvantages of AI
Advantages:
One of the biggest achievements of Artificial Intelligence is that it can reduce human error.
AI can be very helpful in risky situations where humans can't reach or find difficult survival. Such as exploring the deepest part of the sea.
With AI, 24*7 support can be provided to the customers using chatbots as customer care.
Repetitive actions can be boring for human beings, but with AI-enabled machines, they can be performed with full efficiency.
It is very helpful in daily activities, such as Google Assistant Alexa, and other virtual assistant technology are helping to make our life easier.
Disadvantages:
The development and maintenance of AI systems are very expensive.
The dependencies of human beings on such technologies making humans lazy.
There is always a fear with AI that if it gets advanced, it may be harmful to humanity.
If inputs are not fed correctly to AI systems, then it may cause harmful results.
 
On the basis of Capability, AI can be divided into mainly three types:
1. Narrow AI or Weak AI: Narrow AI or Weak AI is a basic kind of Artificial Intelligence, which is capable of completing dedicated tasks with intelligence. The current version of AI is narrow AI.
Narrow AI can only perform the specific task and not beyond its limitation, as they are trained for one task only. It is programmed to do a specific task such as Play Chess, Checking Weather, etc.
2. General AI:
Artificial General intelligence or "Strong" AI defines the machines that can show human intelligence. We can say, Machines with AGI can successfully perform any intellectual task that a human can do. This is the sort of AI that we see in movies like "Her" or other sci-fi movies in which humans interact with machines and operating systems that are conscious, sentient, and driven by emotion and self-awareness.
Currently, this type of intelligence does not exist in the real world and only exist in researches and movies. However, researchers across the world are working to develop such machines, which is still a very difficult task.
3. Super AI
Super AI refers to AI that is self-aware, with cognitive abilities that surpass that of humans. It is a level where machines are capable of doing any task that a human can do with cognitive properties. However, Super AI is still a hypothetical concept, and it is a challenging task to develop such AI-enabled machines.
On the basis of Functionality:
1. Reactive Machines
Reactive machines are the basic types of AI, which don't store memories or past experiences for their actions. These types of AI machines only focus on current scenarios and work as per the requirement with the best possible actions. IBM's Deep Blue is an example of a reactive machine.
2. Limited Memory
Limited memory can store some memory or past experiences for a limited time period. Some examples of limited memory are Self-driving cars.
3. Theory of Mind
Theory of Mind is the type of AI which are capable of understanding human emotions, and interact with the human in their way. However, such AI machines are yet not developed, and developers and researchers are making efforts for creating such AI-enabled machines.
4. Self-awareness
Self-awareness AI is the future of Artificial Intelligence, which will have its own awareness, sentiments, and consciousness. This AI is only a hypothetical concept and will take a long journey and challenges to create such AI.
Applications of AI
1. Game Playing:
AI is widely used in Gaming. Different strategic games such as Chess, where the machine needs to think logically, and video games to provide real-time experiences use Artificial Intelligence.
2. Robotics:
Artificial Intelligence is commonly used in the field of Robotics to develop intelligent robots. AI implemented robots use real-time updates to sense any obstacle in their path and can change the path instantly. AI robots can be used for carrying goods in hospitals and industries and can also be used for other different purposes.
3. Healthcare:
In the healthcare sector, AI has diverse uses. In this field, AI can be used to detect diseases and cancer cells. It also helps in finding new drugs with the use of historical data and medical intelligence.
4. Computer Vision:
Computer vision enables the computer system to understand and derive meaningful information from digital images, video, and other visual input with the help of AI.
5. Agriculture:
AI is now widely used in Agriculture; for example, with the help of AI, we can easily identify defects and nutrient absences in the soil. To identify these defects, AI robots can be utilized. AI bots can also be used in crop harvesting at a higher speed than human workers.
6. E-commerce
AI is one of the widely used and demanding technologies in the E-commerce industry. With AI, e-commerce businesses are gaining more profit and grow in business by recommending products as per the user requirement.
7. Social Media
Different social media websites such as Facebook, Instagram, Twitter, etc., use AI to make the user experiences much better by providing different features. For example, Twitter uses AI to recommend tweets as per the user interest and search history.
Prerequisites for Artificial Intelligence
As a beginner, below are some of the prerequisites that will help to get started with AI technology.
Strong knowledge of Mathematics mainly, Calculus, Linear Algebra, Statistics and probability.
A good experience in programming languages like Java, Python, R.
A strong understanding of algorithms.
Good background in data analytics skills.
Challenges with AI
Lack of data or poor-quality data
One of the big challenges with AI is that we don't have enough data to work with AI systems, or data we have is of poor quality or unstructured. AI depends on data for its working and requires a huge amount of data for a good result, but in the real world, data is available either in raw form or unstructured form that contains lots of impurities and missing values that cannot be processed or analyzed. Hence the processing of such data is a big task for organizations, and it takes lots of effort and is a time-consuming process.
Insufficient IT infrastructure
There is still a lack of IT infrastructures, mainly in start-ups, which is a big issue in AI researches and development.
Lack of AI talent
AI is growing continuously day by day with rapid speed, and more people are accepting the proven ideas of AI. The growing rate of AI also needs developers of AI tech. However, the professionals with full scales skills to develop high-level AI implementations are still lacking, which is also one of the big challenges with AI.
Computing Power
Computing power has always been a big issue in the IT industry, but day by day, this issue has been resolved. However, with the development of AI, this issue has arisen again. Deep learning and the processing of neural networks, which are part of AI, require a high level of computing power, and are a major challenge for the tech industries. Mainly for start-ups, collecting money and such high computing power to process the data is a big deal.
Legal Issues
One of the latest challenges with AI is that now organizations need to be wary of AI. The legal issues are raised for concern that if AI collects sensitive data, that may be a violation of federal laws.
Although it is not illegal, industries need to be careful of any supposed impact that might negatively affect their organization.
Conclusion
Artificial Intelligence is undoubtedly a trending and emerging technology. It is growing very fast day by day, and it is enabling machines to mimic the human brain. Due to its high performance and as it is making human life easier, it is becoming a highly demanded technology among industries. However, there are also some challenges and problems with AI. Many people around the world are still thinking of it as a risky technology, because they feel that if it overtakes humans, it will be dangerous for humanity, as shown in various sci-fi movies. However, the day-to-day development of AI is making it a comfortable technology, and people are connecting with it more. Therefore, we can conclude that it is a great technology, but each technique must be used in a limited way in order to be used effectively, without any harm.



Advancement in robotic technology has made a positive contribution in many industries including the mining industry. Intelligent robotic systems are especially fast becoming of interest due to their successful application in many areas where safety is critical.
Even so, robots still continue to rely on humans to control them and in some instances, help fulfill their missions. At the present, the most prevalent means of controlling intelligent robots is by use of regular Remote Control (RC). This means makes use of transmitters and receiver devices which are incorporated in the robots.
Remote controlled robots invariably make use of human control since there has to be an operator giving the robot instructions in real time. However, autonomous control is in some instance the most desirable form of control sine it removes the need for human control. Recent developments have made autonomous control realizable for intelligent robotic systems.
How Autonomous Control Works
Autonomous by definition means having the power to govern self and as such, autonomous controllers possess the ability for self governance in the performance of various tasks.
In practice, autonomous control systems make use of Global Positioning System (GPS) devices that are built into the control system of the intelligent robots. An autonomous controller has the capacity to plan the necessary sequence of control actions that should be taken in order to achieve set goals.
The architecture of an autonomous control system is typically made of three levels. The lowest level is the Execution level which is the interface between the robot and its environment through the use of sensors and actuators (Antsaklis, Passino and Wang 23). The Execution level has a number of control algorithms which are used in the operation of the robot.
The middle level is the Coordination level which interfaces the actions of the top and lower level s in the architecture. The higher levels issue commands to the lower levels and responsive data flows from bottom to top.
An intelligent autonomous controller is at best a complex series of systems with differing performance requirements. Even so, all autonomous controls make use of deterministic feedback controls in their operation.
This feedback requires that a particular task be completed at a certain minimum time or using certain minimum energy. The control algorithms developed for autonomous controllers are built with uncertainty in mind. This is because robots in underground mining operate in areas where which are highly dynamic and intelligent decision making is invaluable.
Ridley and Corke state that the speed of a vehicle traveling a complex path under autonomous control should be continuously regulated according to the physical conditions of the path (30). Roberts et al proposes that robots utilize scanning laser rangefinder to avoid obstacles that may be in the path (194).
For all the talks of autonomy, it must be remembered that even with autonomous controllers, human beings should possess the ultimate authority on the activities being carried out. Antsaklis, Passino and Wang propose that humans should have ultimate authority to override the control of autonomy functions at will (24).
The reason for this is that human beings have better foresight than the robotics and also, humans can prioritize on tasks based on the desired goals. In general, human beings have primacy over the robotics since robots are at the end required to fulfill the goals and objectives set by human beings.
Merits of Autonomy
There are a number of reasons why underground intelligent robots are favored over the use of manned machines. To begin with, the situation of the mines may be very risky and an accident such as a mine collapse may result in the loss of life. An autonomous robotic will not require any human involvement and as such, the safety of human beings is guaranteed.
Another obvious advantage of the autonomous robotic device is that it cannot suffer from errors that a human operator can introduce to the operations. When using conventional remote control, the human operator may make errors of judgment which may result in the loss of the robotic. This loss will have huge financial repercussions for the mining firm. An autonomous robotic will always choose the safest and most efficient means of achieving its goals and will not suffer from any error of judgment.
The efficiency of the intelligent robotic is greatly increased once autonomy is granted. When under a human controller, the full potential of the robot may not be realized since the operator may operate under some perceived limitations.
Autonomous robotics make use of complex computational algorithms to process the information gathered and from this, they come up with the most effective and efficient means to carry out a task (Roberts et al., 195).
In addition to this, the speed of response is significantly increased with autonomous controller as compared to response from human operators. In addition to this, the autonomous robotics’ performance increases with its use. This is because the robotic is able to enhance its performance by learning while under operation. By learning from previous encounters, efficiency is increased even more.
An autonomous robot possesses the capacity to deal with new and unexpected situations that may arise within its limits. This is possible in robotics with a high degree of autonomy where the autonomous controller has the ability to perform some hardware repairs should one of its components fail (Ridley and Corke, 33).
This is a very desirable feature since robots which operate in underground mining venture into areas which are inaccessible of highly unsafe for humans.
As a matter of fact, some of the tasks performed by the intelligent robotic are mundane in nature and time consuming. Such tasks include taking of measurements on toxicity levels deep underground and moving from one point to another through a predetermined path to name but a few.
An autonomous controller will be able to relieve the human operator of the mundane and time consuming tasks therefore increasing efficiency (Antsaklis, Passino and Wang 22). In addition to this, robotics have the advantage of enhanced reliability since they are not prone to overlooking any procedure as human operators are.
Conclusion
Intelligent robots have managed to meet some of the challenges that are faced in underground mining. This is because robots are able to perform tasks in environments that are too dangerous for human beings. Robots with autonomous control promise to further increase the efficiency of robotics in mining therefore increasing their worth to the industry.
While at the moment most of the autonomously controlled robotics are very expensive and used by the military and in space missions, research suggests that better, less expensive and more efficient and adaptive robots will be available in future. This will increase the prevalence of use for autonomous robotics in the mining industry with greater productivity being achieved.


Calculators cannot be regarded as intelligent machines since they are not capable of working in the absence of human beings and cannot be taught. They are basically made to solve problems that people can readily solve. Regardless of speed and the complexity of mathematical problems that they can solve, all that they do is to accept some input and generate desired output.
They may be fast but that does not mean they are intelligent since they only generate what was previously programmed and fed into them. According to Levy (2010) “the aim of Artificial Intelligence is not to regurgitate what has previously been programmed by merely solving a problem. Artificial Intelligence should instead help humans come up with entirely new and different ways of solving problems”.
Unlike other disciplines that are well defined, Artificial Intelligence (AI) lacks clear details that can readily make it to be understandable. We all know how easy it is to distinguish between chemistry, physics, astronomy, biology, mathematics, languages, art, and music because all these disciplines are well defined (Russell and Norvig, 2006).
There lacks clear definition of AI that can be widely accepted, in other words AI lacks clearly defined goals. Artificial Intelligent systems should be able to learn from experience with the aim of improving themselves, in other words, intelligent machines should be those that are capable of learning.
History of Artificial Intelligence
Artificial Intelligence may seem to some to be one of the recent subjects of study given its close association with computer technology. On the contrary, AI has a long history which can be traced back to imagination, philosophy and fiction.
Disciplines such as engineering, electronics and others that were invented long ago have had their fare share of influence on AI. Historically, people are know to have applied the use of AI in areas like learning, deduction, and knowledge representation as well as translation, associative memory, theorem translation etc.
Artificial Intelligence has historically existed in the realms of theory. It all began when Homer wrote some mechanical articles about “tripods” waiting to serve the gods at dinner, thus, imaginary mechanical characters have been part of human culture from antiquity.
However, it’s only after renaissance about half a century ago that the AI scientists undertook to build machines that imitated human thought and intelligent behavior with the aim of testing whether Homers theories could be put to practice. As demonstrated in some films like the terminator, Robocop, transformers and others, prospect of machines that can mimic human beings remains in the future but discussion on the implication of such a reality should be encouraged at whatever cost (Levy, 2010).
With an earth whose population has hit a record high of over seven billion and still rising, problems facing humanity are bound to escalate. Terrorism, diseases without cure, global warming, and increasing cases of financial insecurity even among the developing countries as demonstrated by movements like we are the ninety nine percent can overwhelm human beings at some point in future.
Perhaps the invention of intelligent mechanical beings can be the only solution to social, economical and political woes that may overwhelm humanity. Like the ancient philosophers, should not the modern human being who relies on machines more than ever before stretch his imaginations once more and save humanity from a hoard of current and future problems that are all so real? Perhaps governments will some day be required to relocate people to some other planet due to overpopulation on earth.
Descartes who is a famous philosopher suggested the possibility of inventing intelligent machines to help human beings discover who they truly are. Machines can eventually help bring about actual civilization by eliminating limitations of human intelligence that is prone to bias and that can be easily corrupted.
Mechanical men designed to reason like human beings can help eliminate inefficiency in human institutions. They can be used to settle disputes in courts by using mechanical reasoning devices that use rules of logic. Prior to the invention of calculators, mathematics was a preserve for the few.
Its invention did not render the mathematicians obsolete but strengthened their skills all the more and made it possible for many more others to learn the discipline much efficiently and effectively thereby improving humanities output or productivity. In Jewish folklore, there is this artificially created being called Golem that is akin to Mary Shelly’s Frankenstein. Such imaginary characters have always fascinated human imagination. However, such characters have always fueled irrational fear of intelligent machines among people.
The first machine that seemed to emulate human thought was the chess playing machine invented in eighteenth century. Chess is a game that is intellectually demanding since it requires application of too much thought. People often believed that Turk was able to think on its own and thought that the machine could play against a human counterpart on its own.
However, unlike other people, a newspaper writer was able to observe that Turk was a machine since it played so well. It made flawless moves. Imagine a society where no professional ever made a mistake, would it not be perfect and ideal for human existence. Diplomatic rows would be solved free of human emotion and would be based on tradeoffs or win win solutions thereby making wars to be a thing of the past.
No one would ever have to lose his life because of misdiagnosis by a doctor or faulty sentence handed over by a judge to an innocent citizen. The initial studies of AI involved chess which was used for studying inference. In 1997, AI proved to be no maniac’s delusional imagination when the world chess champion, Gary Kasparov was defeated by Deep Blue Program designed to test relevance of artificial intelligence.
Buddhist views on Artificial Intelligence
Philosophy plays a major role in determining what direction is taken by the AI researchers. It is well understood that AI systems cannot be built in the absence of undivided attention from human mind given the very nature of the subject. Another thing that one ought to bear in mind is that AI is a multi-disciplinary subject that requires close consultations among stakeholders from all other disciplines.
Given that Human mind is the most intelligent thing on record, researchers naturally applies the knowledge they have gathered so far concerning its workings in building AI systems. According to Hagen (1999) “the Buddhist perspective on AI is a controversial one given the belief that the only way an individual can achieve enlightment is by suppressing every plan and calculation made by the mind “.
According to Buddhism, an enlightened individual is devoid of common intelligence that shows how the world is made of interacting parts. The individual sees the world differently, he does not plan, classify, build mental assumptions to accommodate his observations and cares little if his actions should succeed or fail.
Contrary to this belief, AI researchers’ endeavors to equip their systems with the ability to learn from past observations or with knowledge derived from day today experiences of the researchers themselves. Artificial Intelligence systems use bits or parts of different information to arrive at decisions.
This means that when designing an AI system, one cannot help but divide the world into interacting parts that can either be relevant or irrelevant depending on the decisions that are to be made by the system. All successful robots and programs are based on this premise. Despite their usefulness to human and environment, Buddhists consider this to be against the natural state of human mind (Hagen, 1999).
Buddhism teaches that all is flux and nothing abides. According to this principle there is no rule or regulation that can be applied constantly with success since change cannot be stopped from taking place by words written in any language. Any concept becomes obsolete with time. Buddhism teaches that change affects everything including our mind and ego that most people consider to be constant. This means that there can be perceptions without a perceiver or feelings without a feeler, interesting indeed (Hagen, 1999).
Buddhism teaches that everything is intimately interconnected and that reality cannot be a composition of parts. This means that everything is everything else. Thus, subdividing reality into parts will eventually provide wrong results. This concept is referred to as chaotic system.
This kind of system cannot be divided into parts with limited controllable interaction. In such a system, work input does not equal work output since a minor change in output can lead to output that is non-proportionately big and with unpredictable changes. An example of such a system is the weather. Predicting weather often involves segmenting a certain area of interest into smaller parts and then applying simplified rules to each section.
The results obtained from each section are combined and calculation of effects of each part of the other parts is done. However, it is a well known fact that not even the strongest of the super computers ever get to produce accurate weather predictions. According to Buddhism, it would be impossible to predict the weather by splitting it into parts. The only way of predicting it would be by considering it to be part of a whole.
This means that one must take into account everything that can directly or indirectly affect the weather, such as the motion of an insect, heat generated by bacteria or even the light emitted by distant galaxies which has the potential of increasing the energy of a few air molecules. According to Buddhism, an intelligent machine can only be created when it is given both the power to think and to become enlightened. Creating a mind that can be enlightened can be a real challenge for developers of AI systems.
Artificial Intelligence and Global Risk
The greatest mistake that is often made by people is to assume too quickly that they understand something. Most people profess to understand the concept of genetically modified organisms, evolution and even artificial intelligence. Advocates of AI agree that AI is known for promising so much while at the same time delivering too little.
AI is certainly not a simple subject, but people often treat it as some sort of fantasy subject that requires little or no attention. This is embarrassing indeed. Consider other disciplines like astronomy whose reputation never gets ruined by promising to create stars from hydrogen and then failing to create even a tiny one. This clearly shows that AI is not a complicated discipline but rather people tend to think they know a lot about it than they actually do.
Villains, dignified men, men of collar you name them, none if asked to press a button that would lead to total destruction of the world would ever agree. They all need a platform from where each can carry out his noble or ignoble duties. Speaking thus, the destruction of the world would definitely be more of an accident than design.
Human thought works in a way that allows it to provide accurate or approximate answers. People can easily tell what risks are capable of causing deaths more than others. However, when asked to be precise, they tend to overestimate risks that cause few deaths and underestimate those that can cause more deaths.
This shows that human thought is often faced with the risk of making errors. Once a group of people were asked by a researcher to estimate the likely causes of deaths in United States, majority of them noted down that homicide caused more deaths than diabetes. Other studies have consistently proven that human judgment cannot be free of errors.
Reports from various quarters noted that people were unwilling to buy flood insurance policies even when they were heavily subsidized. People tend to underestimate threats that can jeopardize their lives due to floods. They are simply not able to conceptualize or imagine a threat that has never taken place (Levy 2010).
People living in flood prone areas will often take comfort of levees and dams built to control floods. However, what they forget is that serious damage could occur should a single uncontrollable flood strike. If people get used to controlling minor threats, they soon become reluctant and tend to treat the occurrence of major hazards as unlikely. Talk of dangers that threaten the very existence of man and nobody will take you serious for no such danger has ever faced humanity.
Can machines use thought to assist human beings?
The search for intelligent life in outer space is nothing new. Through Search for Extra Terrestrial Intelligence program or SETI, scientists have tried without success to determine whether other animals other than man possess intelligence or whether there is possibility of intelligent beings that live in outer space. All these efforts have born no fruit. It must feel lonely indeed being the only beings who are self aware in the universe.
There are numerous fiction movies like star wars and the likes that suggest the possibility of developing artificial intelligence in machines in incredible ways. If anything, achieving such levels of intelligence in machines is still a pipe dream that is yet to be achieved. This does not mean that artificial intelligence is not in use today.
Factories use robotic arms that can handle delicate tasks. Cars are fitted with micro computers that can detect slight changes in driving style and road conditions. The problem is whether AI researchers are able to come up with intelligent machines that are capable of engaging humans in objective dialogue. To understand how this is possible, it would be proper to discuss the difference between people and computers.
Logic in man is not equivalent to computer logic which is discrete. This means that a computer cannot give you any other answer other than a single answer that it was initially programmed to give. This makes it possible to easily plot a computer’s decisions on a decision tree. Each set of discreet decisions taken is represented by a single node. This gives ability to the computer system to be able to search and understand every single one of these decisions.
On the other hand, people do not make static decisions. For instance, if a group of persons were to be asked to state whether Lake X which is 960 feet deep is deep or not they can either give a yes or no answer. This kind of logic referred to as fuzzy logic is certainly not solid. It is mostly based on an individual’s opinion. For a computer, the answer is definite. The answer given b y the computer will have been obtained from some programmed rule like, “Less than 500 feet shallow, yes, more than 500 feet, deep, and no”.
Humans are what they are today as a result of millions of years of evolution. Creating a machine with all human ability within a short period of time would definitely be a daunting task given all the stages that humans had to go through.
Intelligent machines would therefore have to undergo evolutionary processes similar to those of humans in order for them to gain from enough experience and obtain intelligence equivalent to that of humans. Measuring amount of intelligence obtained through a certain degree of evolution can be quite difficult. 60 years ago, a method to determine the level of machine intelligence in comparison to that of man was invented and given the name Turing Test.
Turing Test
Alison MathisonTuring is a scholar who happened to be an outstanding mathematician. He wanted to establish whether it was possible for computer program to possess intelligence. He devised certain rules that would enable him accomplish his task. The rules were in form of a game commonly called the game of imitation. It involves a group of three people playing together, (A) a man, (B) a woman, and (C) an interrogator who can either be a male or female.
C is locked in a room separate from the rest. The interrogator is supposed to identify between A and B which is the machine and who is a person. C does not know the exact names of A and B since they have been labeled X and Y respectively. The interrogator is supposed to say what he or she thinks of x and Y i.e. X = A or X= B, and Y =A or Y=B. The interrogator asks A and B questions (Penrose, etal, 2009).
Turing suggested that if the responses of a computer were real enough, it would be impossible to distinguish between the real person and the computer. People have always wondered whether Turing test was designed to test the smartness of a human as opposed to machine intelligence of fooling the interrogator. Turing test has been used to develop most of the modern chat programs that tends to fool a person that they are conversing with a human.
The person conversing with a human and a machine is made to believe before the game starts that he will be playing with a man and a woman. When the game is over, he or she is asked to state what player between A and B he or she would assign machine status. If the integrator is unable to tell the difference between the machine (advanced computer) and human, then the computer is deemed to have passed intelligence test (Levy, 2010). The test normally takes five minutes.
Scholars have argued that this test cannot be used to define artificial intelligence for a number of reasons:
A computer can imitate human behavior but not necessarily true intelligence.
A computer can be intelligent but not able to chat like a real person.
 
Turing Test cannot articulate consciousness in a machine. Humans sometimes exhibit totally irrational, chaotic, unpredictable and unintelligent behavior. There is also some intelligent behavior that is uncharacteristic of human nature. Artificial intelligence can be faced with major setbacks indeed.
For instance would such machines be able to experience pain and pleasure, make generalizations, generate ideas, use commonsense and so on. Such questions can make the idea of trying to build artificial intelligent systems to seem absolutely ludicrous. Does this mean that efforts to create artificial intelligent systems should be abandoned, absolutely not? One cannot understand something that cannot be created.
Artificial Intelligence Case Study
Somewhere in St. Leo Laboratory, Eddie Brown is fine tuning the behavior of a machine. Scattered around him is a horde of robots some of which resemble small all-terrain motor vehicles. They appear to be kind of lifeless and slow pieces of electronic gadgets. However, these contraptions are kind of curious in that reason bout the environment and react to surrounding changes. Literary speaking, these machines can “think”.
Eddie, a senior artificial intelligence researcher compares the minds of these contraptions to those of knowledgeable insects that have learned to survive. A housefly is intelligent in that it is able to adapt to surroundings by doing those things which it can do well so as to increase its chances of survival. Eddie states that, going by that definition of intelligence, these robots are smart.

In a different Laboratory located elsewhere, Eddie collaborates with fellow researchers in the school of computing to build artificial intelligent systems that can make complicated decisions. These researchers have been charged with the task of exploring new applications.
This is a project of DARPA or defense advanced Research Projects agency. The robots designed should be able to perform two important tasks. First, they should be able to learn from the researchers how to search for biological hazards in rooms. Second, they should be able to detect, intercept and destroy a moving enemy target. The robots should be able to perform these tasks without any assistance from the researchers.
Most universities focus on building robots with low-level performance with basic system guided movements. There are some that embark on projects to build machines with a higher level of reasoning. Researchers in Georgia school of computing are doing everything to integrate the different levels of functionality to build robots with human like behavior for use by private sector and the military (Brooks, 2009).
Building machines which simulate human knowledge and awareness is no mean task. Consider the case of a common human driver on a highway or a route he or she is used to. This person will drive along at ease without being conscious of the act of driving. This is called reflexive behavior.
However, if the driver gets lost, he becomes conscious of driving as he or she tries to find the way out. This is called cognitive reasoning. The artificial intelligence researchers endeavor to make intelligent machines that can think and act as well as be able to learn and apply the required skills.
This task lies squarely within the jurisdiction of specialists who can develop high level, behavior based software for robots. This system of software borrows heavily from neuroscience and psychology. Eddie uses this set of software to control hardware. Sensors are used to enhance both the software and the hardware and help develop and sustain methods through which robots can acquire and process data that they are able to perceive in real time using data and other information from global positioning satellite.
Conclusion
Just like humans, intelligent machines in the foregoing case can be assisted to gain knowledge through the use of various techniques. The most common technique if the Learning Momentum which was discovered by a person called Arkin and his team mates. The robot is taught that if a behavior has nothing wrong with it, then it should continue repeating it.
The other technique is the reinforcement technique. This is just like the stick and carrot technique used to teach kids. Computer generated rewards are used to encourage the robot every time it makes good decisions thereby making it continue repeating the same. The foregoing project undertakes to investigate ways through which intelligent systems can get to interact with humans by instilling psychological properties in them.
Other than the project that was just discussed, researchers from the College of Computing have undertaken to develop a group of 100 miniature robots to imitate a large scale system that includes different genre of machines, humans and robots. The group of robots is expected to work together in an environment they are not used to and which is subject to change from time to time.
Sensors are allowed to be erroneous and able to gather information from different points. The sensors should be able to help the robots detect the movement and position of their counterparts. This acts as the principle means of cooperation and communication. This system is akin to that found in a colony of termites or bees.
The robots will be able to act properly after a long duration of time since they will have been able to identify wrong moves made due to sensor errors. In other words the robots will have used intelligence to solve movement and spatial problems. Hindrances to advancement in the field of artificial intelligence range from intelligence, ethical, conscience, perception, locomotion and power storage (Russell and Norvig, 2006).

